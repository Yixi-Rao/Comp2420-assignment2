{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> COMP2420/COMP6420 - Introduction to Data Management,<br/> Analysis and Security</h1>\n",
    "\n",
    "<h1 align='center'> Assignment - 2</h1>\n",
    "\n",
    "-----\n",
    "\n",
    "|**Maximum Marks**         |**100**\n",
    "|--------------------------|--------\n",
    "|  **Weight**              |  **20% of the Total Course Grade**\n",
    "|  **Submission deadline** |  **4:00PM, Friday, May 29th**\n",
    "|  **Submission mode**     |  **Electronic, Using GitLab**\n",
    "|  **Penalty**             |  **100% after the deadline**\n",
    "\n",
    "\n",
    "## Learning Outcomes\n",
    "The following learning outcomes apply to this piece:\n",
    "- **LO1** - Demonstrate a conceptual understanding of database systems and architecture, data models and declarative query languages\n",
    "- **LO2** - Define, query and manipulate a relational database\n",
    "- **LO3** - Demonstrate basic knowledge and understanding of descriptive and predictive data analysis methods, optimization and search, and knowledge representation.\n",
    "- **LO4** - Formulate and extract descriptive and predictive statistics from data\n",
    "- **LO5** - Analyse and interpret results from descriptive and predictive data analysis\n",
    "- **LO6** - Apply their knowledge to a given problem domain and articulate potential data analysis problems\n",
    "- **LO7** - Identify potential pitfalls, and social and ethical implications of data science\n",
    "- **LO8** - Explain key security concepts and the use of cryptographic techniques, digital signatures and PKI in security\n",
    "\n",
    "\n",
    "## Submission\n",
    "\n",
    "You need to submit the following items:\n",
    "- The notebook `Assignment-2-uXXXXXXX.ipynb` (where uXXXXXXX is your uid) \n",
    "- A completed `statement-of-originality.md`, found in the root of the forked gitlab repo.\n",
    "\n",
    "Submissions are performed by pushing to your forked GitLab assignment repository. For a refresher on forking and cloning repositories, please refer to `Lab 1`. Issues with your Git repo (with the exception of a CECS/ANU wide Gitlab failure) will not be considered as grounds for an extension. Any variation of this will result in a `zero mark`.\n",
    "\n",
    "***** \n",
    "\n",
    "### Notes:\n",
    "\n",
    "* It is strongly advised to read the whole assignment before attempting it and have at least a cursory glance at the dataset in order to gauge the requirements and understand what you need to do as a bigger picture.\n",
    "* Backup your assignment to your Gitlab repo often. \n",
    "* Extra reading and research will be required. Make sure you include all references in your Statement of Originality. If this does not occur, at best marks will be deduced. Otherwise, academic misconduct processes will be followed.\n",
    "* For answers requiring free form written text, use the designated cells denoted by `YOUR WRITTEN ANSWER HERE` -- double click on the cell to write inside them.\n",
    "* For all coding questions please write your code after the comment `YOUR CODE HERE`.\n",
    "* In the process of testing your code, you can insert more cells or use print statements for debugging, but when submitting your file remember to remove these cells and calls respectively. You are welcome to add additional cells to the final submission, provided they add value to the overall piece.\n",
    "* Your code answers will be marked on **correctness** and **readability** of your code, if your marker can't understand your code your marks may be deducted. \n",
    "* Your written answers will be marked on the **correctness**, **depth** and **clarity** of your written answers. If your marker cannot understand your answer, marks may be deducted\n",
    "* Before submitting, restart the kernel in Jupiter Lab and re-run all cells before submitting your code. This will ensure the namespace has not kept any old variables, as these won't come across in submission and your code will not run. Without this, you could lose a significant number of marks.\n",
    "* For written responses, a word limit of 300 words per question applies. There is no minimum word count. After 300 words, the tutors will stop reading your response, marking what has already been said.\n",
    "\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This introduction has been split into three sections, based on the datasets you will be interacting with: **CVE revisited**, **BikeStores**, and **Rumble**.\n",
    "\n",
    "<br>\n",
    "\n",
    "### CVE revisited\n",
    "Sound familiar? We hope so. You are being provided another sample of the NVD CVE dataset from the first assignment, although for a different year. For a refresher, go check the [about.md](./data/cve/about.md) file.\n",
    "\n",
    "<br>\n",
    "\n",
    "### BikeStores\n",
    "To test your SQL muscles, we have provided a database (and the creation scripts) for a sample SQL database called [BikeStores](https://www.sqlservertutorial.net/sql-server-sample-database/). The BikeStores database is modeled off a retail store selling bicycles. We have provided the Database diagram in Q3 for reference.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Rumble\n",
    "One of the goals of this course was to introduce you to a multitude of different scenarios and datasets, and this assignment will be no exception.\n",
    "\n",
    "The WWE Royal Rumble (Further Reading: [Wikipedia](https://en.wikipedia.org/wiki/Royal_Rumble) or [wwe.com](https://www.wwe.com/shows/royalrumble)) is an annual [professional wrestling](https://en.wikipedia.org/wiki/Professional_wrestling) event put on by the [World Wrestling Entertainment (WWE)](https://en.wikipedia.org/wiki/WWE). At the event, the marque match is a 30-man (or now woman!) \"battle royale\". (If none of this makes sense, don't worry. We're about to explain it.)\n",
    "\n",
    "#### What is professional wrestling?\n",
    "Professional Wrestling is a form of entertainment, quite popular in the United States and Japan. \"Wrestlers\" will \"fight\" in \"matches\", which are aimed to combine theater and athleticism. Matches are predetermined, participants are all willing, and the main aim is to entertain the audience. ([Further Reading](https://entertainment.howstuffworks.com/pro-wrestling.htm)).\n",
    "\n",
    "#### So what is a \"Royal Rumble\"?\n",
    "The \"Royal Rumble\" is a type of match that has 3 rules:\n",
    "- Everyone gets allocated an entrance number (so, you start with 2 and new entries come in every so often).\n",
    "- Only way to get rid of someone is to throw them out of the ring.\n",
    "- Last person standing wins.\n",
    "\n",
    "#### So, what has this got to do with the assignment?\n",
    "Good question! All of the above is background information so you understand the dataset. In the interests of assessing your data handling, manipulation and SQL skills, you are going to be implementing an SQL database from the csv data files provided.\n",
    "\n",
    "*****\n",
    "## Data Description\n",
    "You have three (3) datasets to work with in this assignment, broken down as follows:\n",
    "\n",
    "- Question 1 - CVE\n",
    "- Question 3 - BikeStores\n",
    "- Question 4 - Rumble\n",
    "\n",
    "Once again, the CVE dataset is a sizable dataset (roughly 8000 rows and 24 columns), so it is wise to consider your code in terms of complexity to ensure it doesn't take 30 minutes to run a single line.\n",
    "\n",
    "Further reading on the datasets can be found in the following locations:\n",
    "- [CVE about.md](./data/cve/about.md)\n",
    "- [BikeStores about.md](./data/bikestores/about.md)\n",
    "- [Rumble about.md](./data/rumble/about.md)\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Imports\n",
    "# Every Lab import is here, you may need to uncomment additional items as necessary.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "#from scipy import stats\n",
    "#from sklearn.linear_model import LogisticRegression     # Logistic Regression\n",
    "#from sklearn.neighbors import KNeighborsClassifier      # k-Nearest Neighbours\n",
    "from sklearn.preprocessing import LabelEncoder          # encooding variables\n",
    "from sklearn.preprocessing import StandardScaler        # encooding variables\n",
    "from sklearn.model_selection import train_test_split    # testing our models\n",
    "#from sklearn.preprocessing import OneHotEncoder         # nominal variable\n",
    "#from sklearn.metrics import confusion_matrix            # scoring\n",
    "#from sklearn.tree import DecisionTreeClassifier         # decision trees\n",
    "#from sklearn.tree import DecisionTreeRegressor          # decision trees\n",
    "#from sklearn import tree                                # decision trees\n",
    "from sklearn.decomposition import PCA                   # PCA \n",
    "from sklearn.cluster import KMeans                      # KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional modules here as required\n",
    "# It is unlikely that you would need any additional modules, however we had added space here just in case you feel \n",
    "#     extras are required. Note that some justification as to WHY you are using them should be provided.\n",
    "#\n",
    "# Note that only modules in the standard Anaconda distribution are allowed. If you need to install it manually, it is not an accepted package.\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Q1: Probing Products (25 marks)\n",
    "Building off the dataset you initially encountered in Assignment 1, the CVE dataset has made a return for the following question. Note that while the dataset holds the same schema, the Base Scores have been included, and the data is from a different year (2018).\n",
    "\n",
    "The following question is designed to get you to load and process data, and implement a clustering model for the given scenario below. You have been introduced to `KMeans` clustering in the lectures and labs and this would therefore be the assumed clustering method, although you are welcome to supplement this with other clustering methods from the `sklearn` package as you desire.\n",
    "\n",
    "Your scenario is as follows:\n",
    "> Once again, you have assumed the role of a member of a cyber-security team interested in the vulnerability of products. One of your colleagues developed a heuristic that could be used to group CVE entries into relative risk groups that highlight which vulnerabilities need to be patched in products. While this is useful for determining which vulnerabilities should be patched for products that are already within the system, your software procurement team wants to know if there are any products to avoid when buying new products. \n",
    ">\n",
    "> Your procurement team has asked you to develop an automated modelling system (ie: clustering model) to identify software that can be grouped based on their risk. You must decide how many groupings, and what risk level (for example, High, Medium or Low) is appropriate for each group. Risk could be based on the number of CVEs and CVSS v2 metrics that can be associated to a product. The procurement team does not wish to use the CVSS Base Score metric as a clustering metric. They are also only interested in products with more than 3 entries, otherwise they predict there will be bias in the results. Finally, they are only interested in using the CVSS v2 system. \n",
    ">\n",
    "> Based on this clustering model, the procurement team will make risk-based decisions to determine whether it is safe to introduce a product to the system.\n",
    "\n",
    "You will first be asked to import and pre-process the data ready to implement a clustering model. Then, you are on your own in the world of clustering. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Preprocessing\n",
    "To start off, bring in the data and get it ready for clustering. Your tasks are:\n",
    "\n",
    "1. Import the Data. The dataset is available in the location `data/cve/nvdcve18.csv` <span style= 'float: right;'><b>[1 mark]</b></span>\n",
    "2. Prepare the data for a clustering task. You are welcome to use the data processing code that you wrote for the previous assignment.\n",
    "\n",
    "**Note:** While not every part of this section is not directly assessed, you have a number of tasks that will aid in your clustering and data analysis in future questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "cve_db = pd.read_csv(\"data/cve/nvdcve18.csv\")\n",
    "cve_db.drop(['v3_attackComplexity','v3_attackVector','v3_availabilityImpact','v3_confidentialityImpact','v3_integrityImpact',\n",
    "             'v3_baseScore','v3_privilegesRequired','v3_scope','v3_userInteraction','product.description','reference.url','product.versions'],axis=1,inplace = True)\n",
    "cve_db.dropna(inplace = True)\n",
    "\n",
    "def change_AceC(level):\n",
    "    '''Change the v2_accessComplexity to numerical values\n",
    "    '''\n",
    "    if level == \"HIGH\":\n",
    "        return 0.35\n",
    "    elif level == \"MEDIUM\":\n",
    "        return 0.61\n",
    "    elif level == \"LOW\":\n",
    "        return 0.71\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def change_AceV(level):\n",
    "    '''Change the v2_accessVector to numerical values\n",
    "    '''\n",
    "    if level == \"LOCAL\":\n",
    "        return 0.395\n",
    "    elif level == \"ADJACENT_NETWORK\":\n",
    "        return 0.646\n",
    "    elif level == \"NETWORK\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def change_Auth(level):\n",
    "    '''Change the v2_authentication to numerical values\n",
    "    '''\n",
    "    if level == \"MULTIPLE\":\n",
    "        return 0.45\n",
    "    elif level == \"SINGLE\":\n",
    "        return 0.56\n",
    "    elif level == \"NONE\":\n",
    "        return 0.704\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "def change_2_CIA(level):\n",
    "    '''Change the v2_availabilityImpact,v2_confidentialityImpact,v2_integrityImpact to numerical values\n",
    "    '''\n",
    "    if level == \"COMPLETE\":\n",
    "        return 0.66\n",
    "    elif level == \"PARTIAL\":\n",
    "        return 0.275\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# CVSS v2 initialization part-------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "cve_db[\"v2_accessComplexity\"] = cve_db[\"v2_accessComplexity\"].apply(change_AceC)\n",
    "\n",
    "cve_db[\"v2_accessVector\"] = cve_db[\"v2_accessVector\"].apply(change_AceV)\n",
    "\n",
    "cve_db[\"v2_authentication\"] = cve_db[\"v2_authentication\"].apply(change_Auth)\n",
    "\n",
    "cve_db[\"v2_availabilityImpact\"] = cve_db[\"v2_availabilityImpact\"].apply(change_2_CIA)\n",
    "cve_db[\"v2_confidentialityImpact\"] = cve_db[\"v2_confidentialityImpact\"].apply(change_2_CIA)\n",
    "cve_db[\"v2_integrityImpact\"] = cve_db[\"v2_integrityImpact\"].apply(change_2_CIA)\n",
    "cve_db.head()\n",
    "# (ANY ADDITIONAL CELLS AS REQUIRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Building a Clustering Model\n",
    "Based on the scenario above, create a clustering model to group products within the CVE dataset by the risk they may pose. Ensure that:\n",
    "1. You include a detailed visualisation of the clusters. \n",
    "2. You choose an appropriate number of clusters. \n",
    "\n",
    "You should consider whether normalisation and any other data processing steps explored in this course are appropriate for this task.\n",
    "<span style= 'float: right;'><b>[10 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "cve_db['vendor.name'] = LabelEncoder().fit_transform(cve_db['vendor.name'])\n",
    "cve_db['cve.id'] = LabelEncoder().fit_transform(cve_db['cve.id'])\n",
    "cve_db['product.name'] = LabelEncoder().fit_transform(cve_db['product.name'])\n",
    "\n",
    "std = StandardScaler()\n",
    "std_cve_db = std.fit_transform(cve_db[['v2_accessComplexity','v2_accessVector','v2_authentication',\n",
    "                             'v2_availabilityImpact','v2_confidentialityImpact','v2_integrityImpact']])\n",
    "\n",
    "pca2 = PCA(n_components=2)\n",
    "cve_reduced = pca2.fit_transform(std_cve_db)\n",
    "kmc = KMeans(n_clusters=3)\n",
    "kmc.fit(cve_reduced)\n",
    "\n",
    "cve_db['level'] = kmc.labels_\n",
    "\n",
    "\n",
    "# feel free to change the colours to your liking\n",
    "colors=[\"red\",\"blue\",\"green\",\"purple\",\"orange\",\"black\",\"yellow\"]\n",
    "\n",
    "# plotting with different coloured clusters and showing cluster centres\n",
    "plt.figure(figsize=(15,10))\n",
    "for i in range(np.max(kmc.labels_)+1):\n",
    "    plt.scatter(cve_reduced[kmc.labels_== i][:,0], cve_reduced[kmc.labels_==i][:,1], label=i, c=colors[i], alpha=0.5,s=20)\n",
    "plt.scatter(kmc.cluster_centers_[:,0], kmc.cluster_centers_[:,1], label='Cluster Centers', c=\"black\", s=100)\n",
    "plt.title(\"K-Means Clustering of cve Data\",size=20)\n",
    "plt.xlabel(\"Principle Component 1\", size=16)\n",
    "plt.ylabel(\"Principle Component 2\", size=16)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# (ANY ADDITIONAL CELLS AS REQUIRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Analysing the Clusters\n",
    "With your clustering model complete, analyse the outputs in preparation for showing the results to the procurement team. Your tasks are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Comparison of scores\n",
    "1. Compare the mean of each CVSS v2 metric, including the CVSS v2 Base Score, between all clusters in your model. \n",
    "2. Identify and explain the largest differences in these metrics between the clusters (i.e. what are the defining characteristics of a cluster compared to other cluster(s)?). Ensure that you compare the average CVSS v2 Base Score between each cluster as well.\n",
    "\n",
    "<span style= 'float: right;'><b>[5 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "cve_db_group = cve_db.groupby('level').apply(np.mean)\n",
    "cve_db_group[['v2_accessComplexity','v2_accessVector','v2_authentication','v2_availabilityImpact','v2_confidentialityImpact','v2_integrityImpact','v2_baseScore']]\n",
    "\n",
    "# (ANY ADDITIONAL CELLS AS REQUIRED)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# YOUR RESPONSE HERE\n",
    "    The largest differences in these metrics between the clusters is the v2_integrityImpact, the difference is 0.57, and I think it is the initial value differneces between the v2_integrityImpact are large causes this.\n",
    "    The average CVSS v2 Base Score between each cluster also have some variations, the differencce between cluster 0 and cluster 1 is 1, while cluster 1 and cluster 2 difference is 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Comparison of scores\n",
    "1. Visualise the distribution of the CVSS2 Score between each cluster. \n",
    "2. Answer the following: Without the use of a hypothesis test, does the CVSS2 Score appear to differ significantly between these clusters? (You may reference the previous question rather than reproducing answers)\n",
    "\n",
    "<span style= 'float: right;'><b>[4 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "cluster_baseScore = cve_db_group['v2_baseScore']\n",
    "plt.bar(0,cluster_baseScore[0])\n",
    "plt.bar(1,cluster_baseScore[1])\n",
    "plt.bar(2,cluster_baseScore[2])\n",
    "plt.title(\"Comparison of scores\",size=20)\n",
    "plt.xlabel(\"cluster\", size=16)\n",
    "plt.ylabel(\"base score\", size=16)\n",
    "plt.xticks([0,1,2],[\"0\", \"1\", \"2\"])\n",
    "plt.show()\n",
    "# (ANY ADDITIONAL CELLS AS REQUIRED)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# YOUR RESPONSE HERE\n",
    "The CVSS2 Score differs significantly between these clusters, because we can see that in the graph, three clusters difference is significant, and also in the dataframe of the question 1.3.1, the mean of each CVSS v2 metric also has the same difference tendency when it compared to the graph of this question, in addition, from the graph of the base score, we can infer that the risk level and the base score have a linearly relationship, so the CVSS2 Score differs significantly between these clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Convincing the Procurement Team\n",
    "With your evidence and analysis points well defined, it is now time to present your model and findings to the procurement team.\n",
    "\n",
    "Explain your model, your reasoning for using the particular CVSS metrics as described in the initial context and which you used in Q1.2, and how this model could be used when they are determining what software should be purchased. Include an example of a product in your explanation.\n",
    "<span style= 'float: right;'><b>[5 marks]</b></span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# YOUR RESPONSE HERE\n",
    "    My model use the access Complexity,access Vector,authentication,availability Impact,confidentiality Impact, integrity Impact to predict the risk level, the reason why I choose this is that all the metrics are main variable in calculting the v2 base score, and the base score is related to he risk, the higher the score is, then the risk will also increase.\n",
    "    This model could be used by sending the cvss metrics to the model and predict it, and then check which cluster is the product belongs, then if the risk level is very high in that cluster, therefore the purshased should not be purchased, for example a product (cvss v2 metric is low,network,none,partial,partial,partial respectively ) should belong to medium risk level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code box if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "## Q2: Eager for Ethics (10 marks)\n",
    "While Data Scientists and Data Engineers spend a lot of timing thinking about how to solve a problem, it is important to think about _why_ we solve a problem and what impacts it could have. For the following scenarios, provide a written response to the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Scenario One\n",
    "> Blume, an organisation at the forefront of technology, has recently hired you as a Data Analyst. In your induction, you discover Blume works with a number of government and private industry organisations in data handling processes, while maintaining a copy of the data. This data is then collected, analysed and indiscriminately sold on to a number of other organisations who have used the data to perform a number of questionable practices. These practices include: adjusting prices of health insurance premiums based on a person's eating habits, adjusting rent prices based on income, predictive policing, and selective advertising. \n",
    "\n",
    "What are some of the potential ethical issues that could arise in Blume's business practices? What harms _could_ arise from the outcomes of Blume's business dealings? Provide examples in your response to the questions.\n",
    "<span style= 'float: right;'><b>[4 marks]</b></span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# YOUR RESPONSE HERE\n",
    "    The potential ethical issues is 'Weblining' and 'Unfair Discrimination' and 'The Digital Surveillance Economy'. For example, the pratice of predictive policing will cause 'Unfair Discrimination' because someone will be arrested depending on his colour of skin or the gender and the 'Weblining' issue is caused by adjusting prices of health insurance premiums based on a person's eating habits, adjusting rent prices based on income 'The Digital Surveillance Economy' is caused by selective advertising.\n",
    "    Property Damage and Financial Loss  will arise when the 'Weblining' happens, since some people who are fat will spent more money on health insurance premiums, and some people who have a high income will pay more rent. Reputation or ConÔ¨Ådence Loss will arise when 'predictive policing' arrest the wrong person due to discrimination.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Scenario One (cont.)\n",
    "As a data analyst for the company, what should you be conscious of when working there and handling the sensitive data that you could be exposed to?\n",
    "<span style= 'float: right;'><b>[3 marks]</b></span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# YOUR RESPONSE HERE\n",
    "    I should fully comply with Code of Professional Conduct. And I should understand the Problem Domain, Understand each source of this data and investigate whether it's tenable.\n",
    "    Then I should aware of the data security, I should investigate, minimise, manage and mitigate the risks of erroneous data merger.\n",
    "    I should ensure I have the Expertise and Understand the data analytics techniques, and aware of the Suitability of the Tool and the Data, be conscious of the Inappropriate Data as well.\n",
    "    At last, I should be aware of the confidentiality, availability, integrity of the data to be maintain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Scenario Two\n",
    "> You've now been working as a Data Analyst at Blume for over a year, and recently Blume has been featured in the news for unethical business practices. A whistle-blower organisation, DedSec, formally approaches you individually, offering to pay you for access to Blume's data. DedSec claims that _\"we will be the watch dogs\"_, reviewing Blume's practices from inside their systems and reporting any issues they find publicly.\n",
    "\n",
    "Discuss the ethical issues with letting DedSec have access to Blume's systems. Provide examples in your response.\n",
    "<span style= 'float: right;'><b>[3 marks]</b></span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# YOUR RESPONSE HERE\n",
    "    1.'Data Expropriation for Unintended Purposes' issue, for example, the DedSec maybe use the data of blume to do some illegal thing such as using blume information to buy some illegel thing.\n",
    "    2.'Data Quality Assurance' issue, DedSec may breach its claim and then change the data of brume and do some pratice. \n",
    "    3.'Data Security' issue, for example, the DedSec will review Blume's practices from inside their systems and report any issues they find publicly, reporting the data to public will not keep the data save thereby the Security is no longer to be save. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "## Q3: Serious SQL (20 marks)\n",
    "Consider the following scenario.\n",
    "\n",
    "> You are applying for a job as a database developer for an unnamed wrestling company. Part of the job description includes creating an automation system for running SQL queries. During the hiring process, the interviewers want to ensure you understand the SQL language. They have provided a set of questions to be answered by you, and your responses will later be reviewed by them. They are unwilling to give you access to their real database (which is mysteriously missing), so they have provided an SQLite3 database and asked you to interact with it using Python. \n",
    "\n",
    "\n",
    "Based on the above scenario, you have been asked to answer a number of questions to test your skills. You will be using the BikeStores database for this question. The database model is as follows:\n",
    "\n",
    "![bikestores_example](./img/bikestore_database.png)\n",
    "\n",
    "\n",
    "**Note:** You will notice the above diagram uses a different ER notation than described in the lectures. The lecture slides use [Chen's Notation](https://www.vertabelo.com/blog/chen-erd-notation/), while this diagram uses [Crow's Foot Notation](https://www.vertabelo.com/blog/crow-s-foot-notation/). Either is acceptable in this instance. For a quick intro to crow's foot notation, check out this [LucidChart reference page](https://www.lucidchart.com/pages/ER-diagram-symbols-and-meaning).\n",
    "\n",
    "In the following questions, you will be asked to execute the SQL statement, and explain any reasoning as necessary. Data can be formatted as raw printed output or a Pandas DataFrame. Recall the use of the `fetchone` and `fetchall` functions on an sqlite cursor for retriving information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS YOUR CONNECTION BLOCK, DO NOT MODIFY THIS. \n",
    "# OTHERWISE, YOU WILL NOT BE ABLE TO READ THE DATABASE\n",
    "def create_connection(db_file):\n",
    "    \"\"\" Connect to the specified SQLite database, if not exist, create a new one (in memory);\n",
    "    :db_file: location of db to connect to\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(\"Connection established!\")\n",
    "    except Error as e:\n",
    "        print(\"Error Connecting to Database\")\n",
    "        raise(e)\n",
    "    return conn\n",
    "\n",
    "dbfile_prod = \"./data/bikestores/production.db\"\n",
    "dbfile_sales = \"./data/bikestores/sales.db\"\n",
    "conn = create_connection(dbfile_prod) \n",
    "cur = conn.cursor()\n",
    "cur.execute('attach database \"' + dbfile_prod + '\" as production;')\n",
    "cur.execute('attach database \"' + dbfile_sales + '\" as sales;')\n",
    "# remember to close the connection when everything is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Customised Customers\n",
    "List the number of customers in the database.\n",
    "<span style= 'float: right;'><b>[2 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "pd.read_sql_query('''SELECT COUNT(customer_id)\n",
    "                     FROM (SELECT customer_id\n",
    "                           FROM customers\n",
    "                           GROUP BY customer_id);''',conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Avoid the Coast\n",
    "List the customers who **do not** live in the state of California (CA) **nor** the state of New York (NY).\n",
    "<span style= 'float: right;'><b>[2 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "pd.read_sql_query('''SELECT * \n",
    "                     FROM customers\n",
    "                     WHERE state != 'CA' AND state != 'NY';''',conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Short on Stock\n",
    "List the amount of stock available for the `Heller Shagamaw Frame - 2016` product in each store.\n",
    "<span style= 'float: right;'><b>[2 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "pd.read_sql_query('''SELECT store_name,quantity\n",
    "                     FROM (SELECT store_id,quantity\n",
    "                           FROM stocks NATURAL JOIN products\n",
    "                           WHERE product_name = 'Heller Shagamaw Frame - 2016') NATURAL JOIN stores; ''',conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: Lost Shipments\n",
    "List the earliest and latest order(s) (by order date) for order(s) that have not been shipped (ie: have no shipping date.)\n",
    "\n",
    "Note: This should be performed in a single SQL query.\n",
    "<span style= 'float: right;'><b>[3 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "pd.read_sql_query('''SELECT * \n",
    "                     FROM orders\n",
    "                     WHERE shipped_date IS NULL\n",
    "                     ORDER BY order_date DESC;''',conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5: Started off Simple\n",
    "List the _Order IDs_ and all of the product information of all products that _Ollie Zimmerman_ has ordered. \n",
    "\n",
    "Note: There may be more than 1 Order ID.<span style= 'float: right;'><b>[3 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.read_sql_query('''SELECT *\n",
    "                     FROM (SELECT product_id\n",
    "                           FROM (SELECT order_id\n",
    "                                 FROM customers NATURAL JOIN orders\n",
    "                                 WHERE first_name = 'Ollie' AND last_name = 'Zimmerman') NATURAL JOIN order_items) NATURAL JOIN products;''',conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6: Staff Stuff\n",
    "List the _Staff ID_ and _first_name_ of each staff member, along with the number of orders processed by that staff member and the total sum of the price of orders processed by that staff member. Name the columns: Staff_ID, Staff_Name, Orders and Total_Price respectively.\n",
    "\n",
    "**Note:** You may exclude staff that haven't processed any orders. <span style= 'float: right;'><b>[4 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "\n",
    "pd.read_sql_query('''SELECT Staff_ID, Staff_Name, Orders,Total_Price\n",
    "                     FROM (SELECT orders.Staff_id AS Staff_ID,first_name AS Staff_Name, count(order_id) AS Orders\n",
    "                           FROM orders INNER JOIN staffs ON orders.staff_id = staffs.staff_id\n",
    "                           GROUP BY orders.staff_id) NATURAL JOIN (SELECT staff_id AS Staff_ID , sum(quantity * list_price * (1 - discount)) AS Total_Price\n",
    "                                                                   FROM orders NATURAL JOIN order_items\n",
    "                                                                   GROUP BY staff_id);''',conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7: Haro in 2018\n",
    "List the first name, last name, and email of every customer who, in 2018, ordered any products manufactured by the _Haro_ brand. Sort by _last_name_ then by *first_name*, with \"A\" at the top and \"Z\" at the bottom. Ensure there are no duplicate entries.\n",
    "<span style= 'float: right;'><b>[4 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "pd.read_sql_query('''SELECT first_name,last_name,email\n",
    "                     FROM customers NATURAL JOIN (SELECT DISTINCT customer_id\n",
    "                                                  FROM (SELECT product_id\n",
    "                                                        FROM products NATURAL JOIN brands\n",
    "                                                        WHERE brand_name = 'Haro') NATURAL JOIN (SELECT order_id,customer_id,product_id\n",
    "                                                                                                 FROM orders NATURAL JOIN order_items\n",
    "                                                                                                 WHERE order_date > 20171231 AND order_date < 20190101))\n",
    "                     ORDER BY last_name,first_name\n",
    "                     ''',conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "## Q4: Dubious Databases (25 marks)\n",
    "Consider the following scenario:\n",
    "\n",
    "> You've been successful in your application as a database developer for an unnamed wrestling company. Your managers wish to understand why it is so difficult to search through the results of past events, and to your surprise, you find all the results as .csv files on your computer. The previous database developer never bothered to make a database, and manually kept track of all the information of the events - making it very difficult for quick searches. You've been tasked with building a database for the company to use to fix this. Rather than starting from scratch, you're hoping you can use the event results to start filling in information. The first folder you find is called `rumble`.\n",
    "\n",
    "Your task is as follows:\n",
    "- Design a database to meet the requirements specified below.\n",
    "- Draw a simple ER diagram showing the relationship between the tables.\n",
    "- Implement the database in an SQLite database.\n",
    "- Import the csv files from the `rumble` folder and enter the data into the database.\n",
    "- Complete the final search request as described by your manager below.\n",
    "\n",
    "The following is the requirements brief that was provided to you by your manager in an email:\n",
    "> Afternoon newbie,\n",
    ">\n",
    "> Our company runs a really special match called the *Royal Rumble* but so far, we haven't been keeping digital records of it very well. We've been running it for a while, so a lot of it is paper-based, but the previous database developer had stored it all in text files which you should have access to.\n",
    ">\n",
    "> So basically, the company is built on events, which we run once a year. An event would normally have a title, year, location, and attendance; although we may have to enter some of that information by ourselves later.\n",
    ">\n",
    "> Each event has a series of matches. Initially we only ran one match at each event, but lately we've been doing one for males and one for females. A __match__ has the following attributes:\n",
    "> - a title, \n",
    "> - list of participants, \n",
    "> - how long each respective participant was in the match, \n",
    "> - how many people they eliminated, \n",
    "> - one winner, and \n",
    "> - how long the match went for. \n",
    ">Some other organisations rate their matches, although I don't like that so don't worry about that aspect.\n",
    ">\n",
    "> Finally, the __wrestlers__ or __participants__ will have the following attributes:\n",
    "> - a stage name, \n",
    "> - real name, and \n",
    "> - gender. \n",
    "> \n",
    ">We will have to enter a lot of this information later, but at least we can enter in the information we have. You can just assume the records contain the stage name, not the real name.\n",
    ">\n",
    "> Don't worry about formatting issues; for example, if a wrestler's name is \"*Mankind*\" one year, then \"*Cactus Jack*\" another year, and \"*Dude Love*\" the year after, you can just pretend they're different wrestlers. People change their names all the time. Similarly, if the previous database designer entered a wrestler as \"*D'Lo Brown*\" in one place and \"*DLo Brown*\" in another place, you can also pretend that's two wrestlers. We'll fix that up manually later.\n",
    ">\n",
    "> After you've done all that, can you show me the match title and duration of all the events that Steve Austin won? I believe he goes by \"*Stone Cold Steve Austin*\" and \"*Steve Austin*\".\n",
    ">\n",
    "> Good luck!\n",
    "> Adam Cole\n",
    "\n",
    "__Note:__ the data is unlikely in an ideal format, so you will need to explore and understand the data yourself before getting started. See the [Rumble about.md](./data/rumble/about.md) for additional details (in a real-world situation, even this information would not be provided). We will only be able to clarify any errors or unreasonably ambiguous details. Remember to state all assumptions beforehand.\n",
    "\n",
    "__Note 2:___ Diagrams can be drawn by hand and scanned/photographed, or you can use a tool such as [draw.io](https://draw.io). You should include the diagram in the `img` folder, and import it into a markdown box in your notebook. You can use the command `![er.png](./img/er.png)` where `er.png` is the name of your ER diagram file.\n",
    "<span style= 'float: right;'><b>[25 marks]</b></span>\n",
    "\n",
    "![2420NewEr](./img/2420NewEr.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# YOUR RESPONSE HERE\n",
    "Assumption:\n",
    "    1. for each year event, the match may or may not be hold due to some reasons(e.g. cor-19) and if a match is must be hold by a event\n",
    "    2. I add some addtional attributes such as the 'Order', 'Eliminated by' into entity 'participate_in', because the cve file contains those attributes.\n",
    "    3. The match title is just the combination of the year and the gender.\n",
    "    4. the wrestlers can attend many matches, since they can attend the matches which are hold in different year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "dbfile_rum = \"./data/rumble/rumDB.db\"\n",
    "conn_db = create_connection(dbfile_rum)\n",
    "cur_ru = conn_db.cursor()\n",
    "# (ANY ADDITIONAL CELLS AS REQUIRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ru.execute('''CREATE TABLE events \n",
    "                     (year INT,\n",
    "                      event_title VARCHAR(50),\n",
    "                      location VARCHAR(50),\n",
    "                      attendance VARCHAR(1000),\n",
    "                      PRIMARY KEY(year));''')\n",
    "\n",
    "cur_ru.execute('''CREATE TABLE matches \n",
    "                     (winner VARCHAR(30),\n",
    "                      match_title VARCHAR(30),\n",
    "                      duration VARCHAR(30),\n",
    "                      list_participants VARCHAR(1000),\n",
    "                      e_year INT,\n",
    "                      PRIMARY KEY (match_title),\n",
    "                      FOREIGN KEY (e_year) REFERENCES events(year));''')\n",
    "\n",
    "cur_ru.execute('''CREATE TABLE wrestlers\n",
    "                     (real_name VARCHAR(50),\n",
    "                      stage_name VARCHAR(50),\n",
    "                      gender VARCHAR(10),\n",
    "                      PRIMARY KEY (real_name));''')\n",
    "\n",
    "cur_ru.execute('''CREATE TABLE participate_in\n",
    "                     (order_player VARCHAR(30),\n",
    "                      player_name VARCHAR(50),                    \n",
    "                      game_title VARCHAR(30),                      \n",
    "                      brand VARCHAR(50),                      \n",
    "                      eliminated_number INT,                      \n",
    "                      playing_time VARCHAR(30),                      \n",
    "                      eliminated_by VARCHAR(30),                        \n",
    "                      PRIMARY KEY (player_name,game_title),\n",
    "                      FOREIGN KEY (player_name) REFERENCES wrestlers(real_name),\n",
    "                      FOREIGN KEY (game_title) REFERENCES matches(match_title)\n",
    "                      )''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cve_to_db(name):\n",
    "    year = name[0:4]    \n",
    "    match_title = year + name[4]\n",
    "    df_event = pd.read_sql_query('''SELECT year FROM events''',conn_db)\n",
    "    if int(year) not in df_event.values:\n",
    "        insert_sql('events','(year)','('+year+\")\")\n",
    "        \n",
    "    df_Rum = pd.read_csv(\"./data/rumble/\" + name)\n",
    "    winnner = df_Rum[df_Rum['Eliminated by'] == 'Winner'].iloc[0,1]\n",
    "    duration = df_Rum[df_Rum['Eliminated by'] == 'Winner'].iloc[0,4]\n",
    "    if duration  == 'Winner':\n",
    "        duration = df_Rum[df_Rum['Eliminated by'] == 'Winner'].iloc[0,5]\n",
    "    \n",
    "    list_of_player = \"\"\n",
    "    \n",
    "    for row in df_Rum.itertuples():\n",
    "        real_name = row[2]\n",
    "        list_of_player = list_of_player + real_name + \";\"\n",
    "        gender = \"male\" if name[4] == \"m\" else \"female\"\n",
    "        #'''add westlters with gender and name '''\n",
    "        df_player = pd.read_sql_query('''SELECT real_name FROM wrestlers''',conn_db)\n",
    "        if real_name not in df_player.values:\n",
    "            insert_sql('wrestlers','(gender,real_name)',str((gender,real_name)))\n",
    "           \n",
    "        if df_Rum.columns[2] == \"Brand\" or df_Rum.columns[2] == \"Brand/Status\":\n",
    "            brand = row[3]\n",
    "            order = row[4]\n",
    "            eliminated_by = row[5]\n",
    "            playing_time = row[6]\n",
    "            eliminations = row[7]\n",
    "            #'''add paticipate_in with 4 column and brand match_title'''\n",
    "            insert_sql('participate_in',\n",
    "                       '(brand,order_player,eliminated_by,playing_time,eliminated_number,game_title,player_name)',\n",
    "                       str((brand,order,eliminated_by,playing_time,eliminations,match_title,real_name)))\n",
    "            \n",
    "        else:\n",
    "            order = row[3]\n",
    "            eliminated_by = row[4]\n",
    "            playing_time = row[5]\n",
    "            eliminations = row[6]\n",
    "            #'''add paticipate_in with 4 column and match title match_title'''\n",
    "            insert_sql('participate_in',\n",
    "                       '(order_player,eliminated_by,playing_time,eliminated_number,game_title,player_name)',\n",
    "                       str((order,eliminated_by,playing_time,eliminations,match_title,real_name)))\n",
    "    \n",
    "    insert_sql( 'matches',\n",
    "                '(match_title,winner,duration,e_year,list_participants)', \n",
    "                str( (match_title,winnner,duration,year,list_of_player) ) )\n",
    "    \n",
    "def insert_sql(table_name,columns,values):\n",
    "    cur_ru.execute('INSERT INTO ' + table_name + ' ' + columns + ' VALUES '+ values +';')\n",
    "    \n",
    "\n",
    "starting_year = 1988\n",
    "while (starting_year != 2021):\n",
    "    male_csv = str(starting_year) + \"m.csv\"\n",
    "    if starting_year >= 2018:\n",
    "        cve_to_db(male_csv)\n",
    "        female_csv = str(starting_year) + \"f.csv\"\n",
    "        cve_to_db(female_csv)\n",
    "        starting_year = starting_year + 1\n",
    "        continue \n",
    "    cve_to_db(male_csv)\n",
    "    starting_year = starting_year + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ruuu = pd.read_sql_query('''SELECT duration,match_title \n",
    "                               FROM matches\n",
    "                               WHERE winner = 'Stone Cold Steve Austin' OR winner = 'Steve Austin' ;''',conn_db)\n",
    "df_ruuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ru.execute(\"DROP TABLE events\")\n",
    "cur_ru.execute(\"DROP TABLE matches\")\n",
    "cur_ru.execute(\"DROP TABLE wrestlers\")\n",
    "cur_ru.execute(\"DROP TABLE participate_in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "## Q5: Shocking Security (20 marks)\n",
    "To finish, please answer the following questions in the _raw text_ boxes provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Secure Signing\n",
    "Consider the following scenario:\n",
    "\n",
    "> Gizmo Technologies has outsourced some work to Tom and Alice, and needs to get them to jointly sign a contract for the work. Since the parties involved are located in different parts of the world, and this is a frequently occurring scenario, Gizmo Technologies decides to come up with a method for doing this electronically. The contract has to be signed by both Tom and Alice. We assume that the contract is transmitted electronically over public channels, so integrity and confidentiality have to be assured. Both Tom and Alice need to be assured that they are both signing the same contract and need to have a copy of the signed contract. The contract needs to be non-repudiable and the process has to be efficient.\n",
    "\n",
    "Describe a method that Gizmo Technologies can use for this purpose that uses cryptographic techniques and meets the above requirements. \n",
    "<span style= 'float: right;'><b>[16 marks]</b></span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# YOUR RESPONSE HERE\n",
    "Assumed that tom get the contract first.\n",
    "1. Gizmo Technologies first using the public key to encrypt the contract, and sent it to Tom\n",
    "2. Tom decrypts the contract using his private key, and do some modifycation (e.g signed his name on it)\n",
    "3. Tom uses the hash function to transform the contract to hash code (or message digests).\n",
    "4. Tom uses his another private key to encrypt the message digests as his digital signatures and attachs it on the contract.\n",
    "5. Tom uses the DES secret key to encrypt all the message that are going to be sent.\n",
    "6. Then Tom using the Alice's public key to encrypt the DES secret key(in step 5). And Tom sents the encrypted 'DES key' and all the encrypted 'message'(in step 5) to Alice\n",
    "7. Alice receives all the stuff, she fisrt uses her private key to decrypt the encrypted 'DES key' to get the secret key and uses it to decrypt the all the encrypted 'message'(in step 5). And ALice finally gets the contract and signatures.\n",
    "8. Alice uses the public key to authenticate the signatures and get the message digests.\n",
    "9. Alice using the same hash function to transform the contract to a new message digests\n",
    "10. Alice compared the latest message digest to the Tom's digests, and check whether it is valid.\n",
    "\n",
    "Then repeated the step 2-10, but this time the sender and receiver is Alice and Gizmo Technologies.\n",
    "N.B. all public keys are issued by CAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: Resilient ito the future\n",
    "As technology evolves, so does the need for secure cryptographic algorithms. With the introduction of quantum computing, the organisations around the world are preparing to migrate towards quantum resistant algorithms.\n",
    "\n",
    "Briefly explain why there is a need for quantum-resistant cryptographic algorithms. Provide an example of a quantum-resistant cryptographic algorithm in your explanation.\n",
    "<span style= 'float: right;'><b>[4 marks]</b></span>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# YOUR RESPONSE HERE\n",
    "    Because the quantum computing is very efficient and fast when it compared to traditional computing. If in the future, the quantum computer is fully developed and Applied to all fields, the traditional cryptographic algorithms will be decrypted quickly, this will influence the RSA,Diffie-Hellman that are based on math or relied on math , therefore the secure communication will no longer to be promise.\n",
    "    for example, McEliece, and SHA3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
